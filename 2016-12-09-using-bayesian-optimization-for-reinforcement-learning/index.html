<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 2.19.43"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><style type="text/css">.gatsby-resp-image-image{width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;color:transparent;}</style><link rel="canonical" href="https://gatsby-casper.netlify.com/2016-12-09-using-bayesian-optimization-for-reinforcement-learning/" data-baseprotocol="https:" data-basehost="gatsby-casper.netlify.com"/><title data-react-helmet="true">Using Bayesian Optimization for Reinforcement Learning</title><link data-react-helmet="true" rel="icon" href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAYAAABw4pVUAAAE9klEQVR4nO2dX0xbVRjAf7sbMy2MyZ8FhaKgZS48uC1IpmhGYsyySOLGGBrDQ0NifEGXOOOmicHtxahswxARoyakMXswyP5gliW6+Gdm82EjDCQLEXRMSpBsrXNKG0GjDwXGlo7LPffe9ph+v6QJab/z9cv9ce45957Tdll17QkSsBLYPvt4BCicfU5Q508gBPQBR4HjwPStQSsSNKwF3gH8blaXhmQB62YfzwIjwF7gyMIgY8Hfy4G3ZwNEhvv4gW7ix3z53JMLe8ibwJ4kFyXcOOZ74UYP2YnISCV7iDvAID5Yt6a0HAHgXWClAdQDvhQXI0AR8LRBfGor6MF2A6hMdRXCPA8ZwF2prkKY524DuCPVVQjzrDTMY4RkIkI0Q4RohgjRDBGiGSJEM0SIZogQzRAhmiFCNEOEaIYI0QwRohkiRDNEiGaIEM0QIZohQjRDhGiGCNGMRLvfF6WsJJOPDlW7UcuS6Dr+I+3Bkdu+HqgrobGh3LX3D0difPXdGACf9lzm6m8zjua3LCTdycv1UL9tLQD129YyNBzhs56fOHXmiiP55ZRlk3Vlubz+ciUH36ggPyfDdj4R4hAV6wto3b/JthQR4iDFvmxa92+ylUOEOEyxL5umgPoH0ESIC9RsKVU+dYkQF/B6Mqh5vEiprSvT3tNnQzQfGHAjtSN0Hr5IsHvUUptAXQlZWSuo2VKK12P+339/abZSbdJDlkiwe5T24AhPNnzJ0HDENL70HhGSNA52/GAa4/XKGJI0hkenGAtddyW3CFFkKva3K3lFiCKZnsXnQ9Go2k1HEaJAWUkmxb7FB+3BobBSbhFikfycDJp3bzSN6+2/qpTfleuQzVU+vjni7HcRpPra5olH1/CAf/X8rffFCEdiyrfj03I9pLGh3NVFrLfa+pTbyinLYToPX+TcwDXl9mnZQ9wgHInR0Tloe+VQeogDRGMz9Jy85MgyrghxAK8ng8aGcj5pe4zKB++0lUuEOEixL5uWfVXs2FqonEOEuMCu5zco95S0XA9JBq/u2kjdc19bbpeWsyyVBSqApoCfgjVeNleZX/Tm5XpoCvgX3dSXCDllWaA9OELzgQFe2XeWcCRmGv9whfWvIhMhCpwbuEZH56BpXLEv2/JmBxGiyKkzV4jGzG+xbyi3NriLEBv8EvrDNCZ7lfSQpGG2SAWwKtPabxiIEEXyczLIy/OYxo3/OmUprwhR5Jmn7l3S/qzL41FLeUWIAju2Fi5poSoam2F41FoPScsLQ1WaAn7uK1lNxfqCJcWf75u0/B7/myXchdi9NeP2iuEcp7+fsNxGTlku0ds/qbQ+IkJcIBqb4YPgkFJbEeICh96/YHkwn0OEOEzbhxdsLeXKLMshxkLXaft40NaOExAhtglHYvScvKS0vpIIEWKR3v5Jfh79HYAvvp1QHitux7Lq2hP/OppRsIUM6pohQjRDhGiGCNEMEaIZIkQzRIhmiBDNECGaIUI0Q4RohgjRDBGiGSJEM0SIZhiA+RZuIVlMG4D13VyCW0wYQHp/OlMvzhvAsVRXIcxzzAC6gFCqKxEYB7oMYBrYneJiBHgJ+Gtu2tsFtKSwmHSnhbiDm65DXgPeS0k56U078WMP3CzkH+BFYCdg7esHBBVGgHrgBeLHHki8c7Eb+Hw2uBaoAIoA+z8fk97MEB+4e4GjxE9R07cG/QfAgxvRPf3evQAAAABJRU5ErkJggg==" type="image/x-icon"/><meta data-react-helmet="true" name="description" content="In this post, we will show you how Bayesian optimization was able to dramatically improve the performance of a reinforcement learning…"/><meta data-react-helmet="true" property="og:site_name" content="Eric Bai"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:title" content="Using Bayesian Optimization for Reinforcement Learning"/><meta data-react-helmet="true" property="og:description" content="In this post, we will show you how Bayesian optimization was able to dramatically improve the performance of a reinforcement learning…"/><meta data-react-helmet="true" property="og:url" content="https://ericbai.co/2016-12-09-using-bayesian-optimization-for-reinforcement-learning/"/><meta data-react-helmet="true" property="og:image" content="https://ericbai.co/static/a8c36305cb787a95e26ebe0c38da0e50/c108b/artificial-intelligence.jpg"/><meta data-react-helmet="true" property="article:published_time" content="2016-12-09T08:00:00.000Z"/><meta data-react-helmet="true" property="article:tag" content="projects"/><meta data-react-helmet="true" property="article:publisher" content="https://www.facebook.com/TheEricBai"/><meta data-react-helmet="true" property="article:author" content="https://www.facebook.com/TheEricBai"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:title" content="Using Bayesian Optimization for Reinforcement Learning"/><meta data-react-helmet="true" name="twitter:description" content="In this post, we will show you how Bayesian optimization was able to dramatically improve the performance of a reinforcement learning…"/><meta data-react-helmet="true" name="twitter:url" content="https://ericbai.co/2016-12-09-using-bayesian-optimization-for-reinforcement-learning/"/><meta data-react-helmet="true" name="twitter:image" content="https://ericbai.co/static/a8c36305cb787a95e26ebe0c38da0e50/c108b/artificial-intelligence.jpg"/><meta data-react-helmet="true" name="twitter:label1" content="Written by"/><meta data-react-helmet="true" name="twitter:data1" content="Eric"/><meta data-react-helmet="true" name="twitter:label2" content="Filed under"/><meta data-react-helmet="true" name="twitter:data2" content="projects"/><meta data-react-helmet="true" name="twitter:site" content="@BaiEric"/><meta data-react-helmet="true" name="twitter:creator" content="@BaiEric"/><meta data-react-helmet="true" property="og:image:width" content="1280"/><meta data-react-helmet="true" property="og:image:height" content="800"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><link rel="preconnect dns-prefetch" href="https://www.google-analytics.com"/><script>
  window.excludeGAPaths=[/^(?:\/preview\/(?:(?!(?:\/|^)\.).)*?)$/];
  function gaOptout(){document.cookie=disableStr+'=true; expires=Thu, 31 Dec 2099 23:59:59 UTC;path=/',window[disableStr]=!0}var gaProperty='UA-XXXX-Y',disableStr='ga-disable-'+gaProperty;document.cookie.indexOf(disableStr+'=true')>-1&&(window[disableStr]=!0);
  if(!(navigator.doNotTrack == "1" || window.doNotTrack == "1")) {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  }
  if (typeof ga === "function") {
    ga('create', 'UA-XXXX-Y', 'auto', {"sampleRate":100,"siteSpeedSampleRate":10});
      ga('set', 'anonymizeIp', true);
      
      
      }
      </script><link as="script" rel="preload" href="/webpack-runtime-4931bb6d0f65d2af2d29.js"/><link as="script" rel="preload" href="/app-bf8ae29db75040b27dc0.js"/><link as="script" rel="preload" href="/commons-db7b0b291fe23d606362.js"/><link as="script" rel="preload" href="/component---src-templates-post-tsx-39d6e0ff64388c07caf2.js"/><link as="fetch" rel="preload" href="/page-data/2016-12-09-using-bayesian-optimization-for-reinforcement-learning/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="post-template"><style data-emotion-css="1f94ib9">html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td,article,aside,canvas,details,embed,figure,figcaption,footer,header,hgroup,menu,nav,output,ruby,section,summary,time,mark,audio,video{margin:0;padding:0;border:0;font:inherit;font-size:100%;vertical-align:baseline;}body{line-height:1;}ol,ul{list-style:none;}blockquote,q{quotes:none;}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none;}table{border-spacing:0;border-collapse:collapse;}img{max-width:100%;}html{box-sizing:border-box;font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;}*,*:before,*:after{box-sizing:inherit;}a{background-color:transparent;}a:active,a:hover{outline:0;}b,strong{font-weight:bold;}i,em,dfn{font-style:italic;}h1{margin:0.67em 0;font-size:2em;}small{font-size:80%;}sub,sup{position:relative;font-size:75%;line-height:0;vertical-align:baseline;}sup{top:-0.5em;}sub{bottom:-0.25em;}img{border:0;}svg:not(:root){overflow:hidden;}mark{background-color:#fdffb6;}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em;}button,input,optgroup,select,textarea{margin:0;color:inherit;font:inherit;}button{overflow:visible;border:none;}button,select{text-transform:none;}button,html input[type='button'],input[type='reset'],input[type='submit']{cursor:pointer;-webkit-appearance:button;}button[disabled],html input[disabled]{cursor:default;}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0;}input{line-height:normal;}input:focus{outline:none;}input[type='checkbox'],input[type='radio']{box-sizing:border-box;padding:0;}input[type='number']::-webkit-inner-spin-button,input[type='number']::-webkit-outer-spin-button{height:auto;}input[type='search']{box-sizing:content-box;-webkit-appearance:textfield;}input[type='search']::-webkit-search-cancel-button,input[type='search']::-webkit-search-decoration{-webkit-appearance:none;}legend{padding:0;border:0;}textarea{overflow:auto;}table{border-spacing:0;border-collapse:collapse;}td,th{padding:0;}html{overflow-x:hidden;overflow-y:scroll;font-size:62.5%;-webkit-tap-highlight-color:rgba(0,0,0,0);}body{overflow-x:hidden;color:#3b474d;font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Oxygen,Ubuntu,Cantarell,'Open Sans','Helvetica Neue',sans-serif;font-size:1.5rem;line-height:1.6em;font-weight:400;font-style:normal;-webkit-letter-spacing:0;-moz-letter-spacing:0;-ms-letter-spacing:0;letter-spacing:0;text-rendering:optimizeLegibility;background:#fff;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;-moz-font-feature-settings:'liga' on;}::selection{text-shadow:none;background:#cbeafb;}hr{position:relative;display:block;width:100%;margin:2.5em 0 3.5em;padding:0;height:1px;border:0;border-top:1px solid #e4eaed;}audio,canvas,iframe,img,svg,video{vertical-align:middle;}fieldset{margin:0;padding:0;border:0;}textarea{resize:vertical;}p,ul,ol,dl,blockquote{margin:0 0 1.5em 0;}ol,ul{padding-left:1.3em;padding-right:1.5em;}ol ol,ul ul,ul ol,ol ul{margin:0.5em 0 1em;}ul{list-style:disc;}ol{list-style:decimal;}ul,ol{max-width:100%;}li{margin:0.5em 0;padding-left:0.3em;line-height:1.6em;}dt{float:left;margin:0 20px 0 0;width:120px;color:#15171A;font-weight:500;text-align:right;}dd{margin:0 0 5px 0;text-align:left;}blockquote{margin:1.5em 0;padding:0 1.6em 0 1.6em;border-left:#e5eff5 0.5em solid;}blockquote p{margin:0.8em 0;font-size:1.2em;font-weight:300;}blockquote small{display:inline-block;margin:0.8em 0 0.8em 1.5em;font-size:0.9em;opacity:0.8;}blockquote small:before{content:'\2014 \00A0';}blockquote cite{font-weight:bold;}blockquote cite a{font-weight:normal;}a{color:#26a6ed;-webkit-text-decoration:none;text-decoration:none;}a:hover{-webkit-text-decoration:underline;text-decoration:underline;}h1,h2,h3,h4,h5,h6{margin-top:0;line-height:1.15;font-weight:700;text-rendering:optimizeLegibility;}h1{margin:0 0 0.5em 0;font-size:5rem;font-weight:700;}@media (max-width:500px){h1{font-size:2.2rem;}}h2{margin:1.5em 0 0.5em 0;font-size:2rem;}@media (max-width:500px){h2{font-size:1.8rem;}}h3{margin:1.5em 0 0.5em 0;font-size:1.8rem;font-weight:500;}@media (max-width:500px){h3{font-size:1.7rem;}}h4{margin:1.5em 0 0.5em 0;font-size:1.6rem;font-weight:500;}h5{margin:1.5em 0 0.5em 0;font-size:1.4rem;font-weight:500;}h6{margin:1.5em 0 0.5em 0;font-size:1.4rem;font-weight:500;}body{background:#f4f8fb;}</style><style data-emotion-css="1mpact1">.css-1mpact1 .site-main{background:#fff;padding-bottom:4vw;}</style><style data-emotion-css="16s8vhf">.css-16s8vhf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;min-height:100vh;}.css-16s8vhf .site-main{background:#fff;padding-bottom:4vw;}</style><div class="css-16s8vhf e1jnnmhu0"><style data-emotion-css="1r9y6t9">.css-1r9y6t9{position:relative;padding:0 4vw;position:relative;padding-top:12px;padding-bottom:12px;color:#fff;background:#0a0b0c no-repeat center center;background-size:cover;}</style><header class="css-1r9y6t9"><style data-emotion-css="s2cjas">.css-s2cjas{margin:0 auto;max-width:1040px;width:100%;}</style><div class="css-s2cjas"><style data-emotion-css="a1zygu">.css-a1zygu{position:relative;z-index:300;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;overflow-y:hidden;height:40px;font-size:1.2rem;}</style><nav class="css-a1zygu"><style data-emotion-css="25mjrn">.css-25mjrn{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;overflow-x:auto;overflow-y:hidden;-webkit-overflow-scrolling:touch;margin-right:10px;padding-bottom:80px;-webkit-letter-spacing:0.4px;-moz-letter-spacing:0.4px;-ms-letter-spacing:0.4px;letter-spacing:0.4px;white-space:nowrap;-ms-overflow-scrolling:touch;}@media (max-width:700px){.css-25mjrn{margin-right:0;padding-left:4vw;}}</style><div class="css-25mjrn e1r0l56b0"><style data-emotion-css="j4gise">.css-j4gise{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;display:block;margin-right:24px;padding:11px 0;color:#fff;font-size:1.7rem;line-height:1em;font-weight:bold;-webkit-letter-spacing:-0.5px;-moz-letter-spacing:-0.5px;-ms-letter-spacing:-0.5px;letter-spacing:-0.5px;}.css-j4gise:hover{-webkit-text-decoration:none;text-decoration:none;}.css-j4gise img{display:block;width:auto;height:21px;}</style><a class="site-nav-logo css-j4gise" href="/">Eric Bai</a><style data-emotion-css="1trdsxq">.css-1trdsxq{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:0 0 0 -12px;padding:0;list-style:none;}.css-1trdsxq li{display:block;margin:0;padding:0;text-transform:uppercase;}.css-1trdsxq li a{display:block;margin:0;padding:10px 12px;color:#fff;opacity:0.8;}.css-1trdsxq li a:hover{-webkit-text-decoration:none;text-decoration:none;opacity:1;}</style><ul role="menu" class="css-1trdsxq"><li role="menuitem"><a href="/about">About Eric</a></li></ul></div><style data-emotion-css="cniab2">.css-cniab2{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:40px;}@media (max-width:700px){.css-cniab2{display:none;}}</style><div class="css-cniab2 e1r0l56b1"><style data-emotion-css="1im5alu">.css-1im5alu{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.css-1im5alu a:last-of-type{padding-right:20px;}</style><div class="css-1im5alu e1r0l56b2"><style data-emotion-css="1l1dftb">.css-1l1dftb{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0;padding:10px;color:#fff;opacity:0.8;}.css-1l1dftb:hover{opacity:1;}.css-1l1dftb svg{height:1.8rem;fill:#fff;}</style><a href="https://www.facebook.com/TheEricBai" target="_blank" title="Facebook" rel="noopener noreferrer" class="css-1l1dftb"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22.675 0h-21.35c-.732 0-1.325.593-1.325 1.325v21.351c0 .731.593 1.324 1.325 1.324h11.495v-9.294h-3.128v-3.622h3.128v-2.671c0-3.1 1.893-4.788 4.659-4.788 1.325 0 2.463.099 2.795.143v3.24l-1.918.001c-1.504 0-1.795.715-1.795 1.763v2.313h3.587l-.467 3.622h-3.12v9.293h6.116c.73 0 1.323-.593 1.323-1.325v-21.35c0-.732-.593-1.325-1.325-1.325z"></path></svg></a><a href="https://twitter.com/BaiEric" title="Twitter" target="_blank" rel="noopener noreferrer" class="css-1l1dftb"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 30 30"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"></path></svg></a><a href="https://instagram.com/baieric" title="Instagram" target="_blank" rel="noopener noreferrer" class="css-1l1dftb"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2.163c3.204 0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849 0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204 0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849 0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zm0-2.163c-3.259 0-3.667.014-4.947.072-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948 0 3.259.014 3.668.072 4.948.2 4.358 2.618 6.78 6.98 6.98 1.281.058 1.689.072 4.948.072 3.259 0 3.668-.014 4.948-.072 4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948 0-3.259-.014-3.667-.072-4.947-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403 0-6.162 2.759-6.162 6.162s2.759 6.163 6.162 6.163 6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zm0 10.162c-2.209 0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796 0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795 0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z"></path></svg></a></div></div></nav></div></header><style data-emotion-css="rtkcef">.css-rtkcef{z-index:100;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;position:relative;padding:0 4vw;}</style><main id="site-main" class="site-main css-rtkcef"><div class="css-s2cjas"><style data-emotion-css="vyvttm">.css-vyvttm{position:relative;z-index:50;}</style><article class="css-vyvttm"><style data-emotion-css="29d3h2">.css-29d3h2{margin:0 auto;padding:6vw 3vw 3vw;max-width:1040px;text-align:center;}@media (max-width:500px){.css-29d3h2{padding:14vw 3vw 10vw;}}</style><header class="css-29d3h2 e1wiqi0y0"><style data-emotion-css="njyqyw">.css-njyqyw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:#738a94;font-size:1.4rem;font-weight:600;text-transform:uppercase;}@media (max-width:500px){.css-njyqyw{font-size:1.2rem;line-height:1.3em;}}</style><section class="css-njyqyw e1wiqi0y1"><style data-emotion-css="et0m70">.css-et0m70{color:#3eb0ef;}</style><time dateTime="2016-12-09T08:00:00.000Z" class="css-et0m70 e1wiqi0y2">9 December 2016</time><style data-emotion-css="m5hopj">.css-m5hopj{display:inline-block;margin:0 6px 1px;}</style><span class="css-m5hopj e1wiqi0y5">/</span><a href="/tags/projects/">projects</a></section><style data-emotion-css="ldwdh4">.css-ldwdh4{margin:0;color:#0b0c0e;}@media (max-width:500px){.css-ldwdh4{font-size:2.9rem;}}</style><h1 class="css-ldwdh4 e1wiqi0y3">Using Bayesian Optimization for Reinforcement Learning</h1></header><style data-emotion-css="1y0hjh3">.css-1y0hjh3{margin:0 -10vw -165px;height:800px;background:#c5d2d9 center center;background-size:cover;border-radius:5px;}@media (max-width:1170px){.css-1y0hjh3{margin:0 -4vw -100px;height:600px;border-radius:0;}}@media (max-width:800px){.css-1y0hjh3{height:400px;}}@media (max-width:500px){.css-1y0hjh3{margin-bottom:4vw;height:350px;}}</style><figure class="css-1y0hjh3 e1wiqi0y4"><div class=" gatsby-image-wrapper" style="position:relative;overflow:hidden;height:100%"><div style="width:100%;padding-bottom:62.5%"></div><img src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAIEAwX/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAAB4dcGsIKV/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAECERIh/9oACAEBAAEFAoVbjEfGaeT/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAVEQEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAgEBPwFn/8QAFRABAQAAAAAAAAAAAAAAAAAAICH/2gAIAQEABj8Cq//EABoQAQEBAAMBAAAAAAAAAAAAAAERABAhMVH/2gAIAQEAAT8hK3J4Y1PnB2LY5a13/9oADAMBAAIAAwAAABCcz//EABcRAAMBAAAAAAAAAAAAAAAAAAEQEUH/2gAIAQMBAT8QE1f/xAAWEQEBAQAAAAAAAAAAAAAAAAABERD/2gAIAQIBAT8QTIZ//8QAGhABAQEBAQEBAAAAAAAAAAAAAREhADEQcf/aAAgBAQABPxDTPwfHlS7Xw05bdqX5XTQBdyciJVa9/9k=" alt="" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/a8c36305cb787a95e26ebe0c38da0e50/f8f18/artificial-intelligence.jpg 930w,
/static/a8c36305cb787a95e26ebe0c38da0e50/c108b/artificial-intelligence.jpg 1280w" sizes="(max-width: 1280px) 100vw, 1280px" /><img loading="lazy" sizes="(max-width: 1280px) 100vw, 1280px" srcset="/static/a8c36305cb787a95e26ebe0c38da0e50/f8f18/artificial-intelligence.jpg 930w,
/static/a8c36305cb787a95e26ebe0c38da0e50/c108b/artificial-intelligence.jpg 1280w" src="/static/a8c36305cb787a95e26ebe0c38da0e50/c108b/artificial-intelligence.jpg" alt="" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div></figure><style data-emotion-css="1apapbg">.css-1apapbg{position:relative;margin:0 auto;padding:70px 100px 0;min-height:230px;font-family:Georgia,serif;font-size:2.2rem;line-height:1.6em;background:#fff;}@media (max-width:1170px){.css-1apapbg{padding:5vw 7vw 0;}}@media (max-width:800px){.css-1apapbg{font-size:1.9rem;}}.css-1apapbg:before{content:'';position:absolute;top:15px;left:-5px;z-index:-1;display:block;width:20px;height:200px;background:rgba(39,44,49,0.15);-webkit-filter:blur(5px);filter:blur(5px);-webkit-transform:rotate(-5deg);-ms-transform:rotate(-5deg);transform:rotate(-5deg);}.css-1apapbg:after{content:'';position:absolute;top:15px;right:-5px;z-index:-1;display:block;width:20px;height:200px;background:rgba(39,44,49,0.15);-webkit-filter:blur(5px);filter:blur(5px);-webkit-transform:rotate(5deg);-ms-transform:rotate(5deg);transform:rotate(5deg);}.css-1apapbg h1,.css-1apapbg h2,.css-1apapbg h3,.css-1apapbg h4,.css-1apapbg h5,.css-1apapbg h6,.css-1apapbg p,.css-1apapbg ul,.css-1apapbg ol,.css-1apapbg dl,.css-1apapbg pre,.css-1apapbg blockquote,.css-1apapbg .post-full-comments,.css-1apapbg .footnotes{min-width:100%;}.css-1apapbg li{word-break:break-word;}.css-1apapbg li p{margin:0;}.css-1apapbg a{color:#000;word-break:break-word;box-shadow:#3eb0ef 0 -1px 0 inset;}.css-1apapbg a:hover{color:#3eb0ef;-webkit-text-decoration:none;text-decoration:none;}.css-1apapbg strong,.css-1apapbg em{color:#0a0b0c;}.css-1apapbg small{display:inline-block;line-height:1.6em;}.css-1apapbg li:first-child{margin-top:0;}.css-1apapbg .gatsby-resp-image-link{box-shadow:none;}.css-1apapbg img,.css-1apapbg video{display:block;margin:1.5em auto;max-width:1040px;height:auto;}@media (max-width:1040px){.css-1apapbg img,.css-1apapbg video{width:100%;}}.css-1apapbg img[src$='#full']{max-width:none;width:100vw;}.css-1apapbg img + br + small{display:block;margin-top:-3em;margin-bottom:1.5em;text-align:center;}.css-1apapbg iframe{margin:0 auto !important;}.css-1apapbg blockquote{margin:0 0 1.5em;padding:0 1.5em;border-left:#3eb0ef 3px solid;}.css-1apapbg blockquote p{margin:0 0 1em 0;color:inherit;font-size:inherit;line-height:inherit;font-style:italic;}.css-1apapbg blockquote p:last-child{margin-bottom:0;}.css-1apapbg code{padding:0 5px 2px;font-size:0.8em;line-height:1em;font-weight:400 !important;background:#e5eff5;border-radius:3px;}.css-1apapbg p code{word-break:break-all;}.css-1apapbg pre{overflow-x:auto;padding:20px;max-width:100%;border:#131517 1px solid;color:#e5eff5;font-size:1.4rem;line-height:1.5em;background:#0e1012;border-radius:5px;}.css-1apapbg pre code{padding:0;font-size:inherit;line-height:inherit;background:transparent;}.css-1apapbg pre code:not(span){color:inherit;}.css-1apapbg .gatsby-resp-iframe-wrapper{margin:1.5em 0 3em;}.css-1apapbg hr{margin:4vw 0;}.css-1apapbg hr:after{content:'';position:absolute;top:-15px;left:50%;display:block;margin-left:-10px;width:1px;height:30px;background:#e4eaed;box-shadow:#fff 0 0 0 5px;-webkit-transform:rotate(45deg);-ms-transform:rotate(45deg);transform:rotate(45deg);}.css-1apapbg h1,.css-1apapbg h2,.css-1apapbg h3,.css-1apapbg h4,.css-1apapbg h5,.css-1apapbg h6{color:#0b0c0e;font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Oxygen,Ubuntu,Cantarell,'Open Sans','Helvetica Neue',sans-serif;}.css-1apapbg h1{margin:0.5em 0 0.2em 0;font-size:4.6rem;font-weight:700;}@media (max-width:500px){.css-1apapbg h1{font-size:2.8rem;}}.css-1apapbg h2{margin:0.5em 0 0.2em 0;font-size:3.6rem;font-weight:700;}@media (max-width:500px){.css-1apapbg h2{font-size:2.6rem;}}.css-1apapbg h3{margin:0.5em 0 0.2em 0;font-size:2.8rem;font-weight:700;}@media (max-width:500px){.css-1apapbg h3{font-size:2.2rem;}}.css-1apapbg h4{margin:0.5em 0 0.2em 0;font-size:2.8rem;font-weight:700;}@media (max-width:500px){.css-1apapbg h4{font-size:2.2rem;}}.css-1apapbg h5{display:block;margin:0.5em 0;padding:1em 0 1.5em;border:0;color:#3eb0ef;font-family:Georgia,serif;font-size:3.2rem;line-height:1.35em;text-align:center;}@media (min-width:1180px){.css-1apapbg h5{max-width:1060px;}}@media (max-width:500px){.css-1apapbg h5{padding:0 0 0.5em;font-size:2.2rem;}}.css-1apapbg h6{margin:0.5em 0 0.2em 0;font-size:2.3rem;font-weight:700;}@media (max-width:500px){.css-1apapbg h6{font-size:2rem;}}.css-1apapbg table{display:inline-block;overflow-x:auto;margin:0.5em 0 2.5em;max-width:100%;width:auto;border-spacing:0;border-collapse:collapse;font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Oxygen,Ubuntu,Cantarell,'Open Sans','Helvetica Neue',sans-serif;font-size:1.6rem;white-space:nowrap;vertical-align:top;}.css-1apapbg table{-webkit-overflow-scrolling:touch;background:radial-gradient(ellipse at left,rgba(0,0,0,0.2) 0%,rgba(0,0,0,0) 75%) 0 center,radial-gradient(ellipse at right,rgba(0,0,0,0.2) 0%,rgba(0,0,0,0) 75%) 100% center;background-attachment:scroll,scroll;background-size:10px 100%,10px 100%;background-repeat:no-repeat;}.css-1apapbg table td:first-child{background-image:linear-gradient( to right,rgba(255,255,255,1) 50%,rgba(255,255,255,0) 100% );background-size:20px 100%;background-repeat:no-repeat;}.css-1apapbg table td:last-child{background-image:linear-gradient( to left,rgba(255,255,255,1) 50%,rgba(255,255,255,0) 100% );background-position:100% 0;background-size:20px 100%;background-repeat:no-repeat;}.css-1apapbg table th{color:#15171A;font-size:1.2rem;font-weight:700;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;text-align:left;text-transform:uppercase;background-color:#f4f8fb;}.css-1apapbg table th,.css-1apapbg table td{padding:6px 12px;border:#e9ebec 1px solid;}@media (max-width:500px){.css-1apapbg{padding:0;}.css-1apapbg:before{display:none;}.css-1apapbg:after{display:none;}}.css-1apapbg code[class*='language-'],.css-1apapbg pre[class*='language-']{background:none;font-family:Consolas,Menlo,Monaco,source-code-pro,Courier New,monospace;font-feature-settings:normal;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;margin-bottom:0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}.css-1apapbg pre[class*='language-']{overflow:auto;padding:1.3125rem;}.css-1apapbg pre[class*='language-']::-moz-selection{background:hsl(207,4%,16%);}.css-1apapbg pre[class*='language-']::selection{background:hsl(207,4%,16%);}.css-1apapbg pre[class*='language-']::-moz-selection,.css-1apapbg pre[class*='language-']::-moz-selection{text-shadow:none;background:hsla(0,0%,100%,0.15);}.css-1apapbg pre[class*='language-']::selection,.css-1apapbg pre[class*='language-']::selection{text-shadow:none;background:hsla(0,0%,100%,0.15);}.css-1apapbg:not(pre) > code[class*='language-']{border-radius:0.3em;background:var(--inlineCode-bg);color:var(--inlineCode-text);padding:0.15em 0.2em 0.05em;white-space:normal;}.css-1apapbg .token.attr-name{color:rgb(173,219,103);font-style:italic;}.css-1apapbg .token.comment{color:rgb(128,147,147);}.css-1apapbg .token.string,.css-1apapbg .token.url{color:rgb(173,219,103);}.css-1apapbg .token.variable{color:rgb(214,222,235);}.css-1apapbg .token.number{color:rgb(247,140,108);}.css-1apapbg .token.builtin,.css-1apapbg .token.char,.css-1apapbg .token.constant,.css-1apapbg .token.function{color:rgb(130,170,255);}.css-1apapbg .token.punctuation{color:rgb(199,146,234);}.css-1apapbg .token.selector,.css-1apapbg .token.doctype{color:rgb(199,146,234);font-style:'italic';}.css-1apapbg .token.class-name{color:rgb(255,203,139);}.css-1apapbg .token.tag,.css-1apapbg .token.operator,.css-1apapbg .token.keyword{color:#ffa7c4;}.css-1apapbg .token.boolean{color:rgb(255,88,116);}.css-1apapbg .token.property{color:rgb(128,203,196);}.css-1apapbg .token.namespace{color:rgb(178,204,214);}.css-1apapbg pre[data-line]{padding:1em 0 1em 3em;position:relative;}.css-1apapbg .gatsby-highlight-code-line{background-color:hsla(207,95%,15%,1);display:block;margin-right:-1.3125rem;margin-left:-1.3125rem;padding-right:1em;padding-left:1.25em;border-left:0.25em solid #ffa7c4;}.css-1apapbg .gatsby-highlight{margin-bottom:1.75rem;margin-left:-1.3125rem;margin-right:-1.3125rem;border-radius:10px;background:#011627;-webkit-overflow-scrolling:touch;overflow:auto;}@media (max-width:672px){.css-1apapbg .gatsby-highlight{border-radius:0;}}.css-1apapbg .gatsby-highlight pre[class*='language-']{float:left;min-width:100%;}</style><section class="post-full-content css-1apapbg e18ncjva0"><div><p>In this post, we will show you how <a href="https://static.sigopt.com/2d66b84dcdbbd7fffad087f58b67a585eb89444c/pdf/SigOpt_Bayesian_Optimization_Primer.pdf">Bayesian optimization</a> was able to dramatically improve the performance of a reinforcement learning algorithm in an AI challenge. We’ll provide background information, detailed examples, code, and references.</p>
<h3>Background</h3>
<p>Reinforcement learning is a field of machine learning in which a software agent is taught to maximize its acquisition of rewards in a given environment. Observations of the state of the environment are used by the agent to make decisions about which action it should perform in order to maximize its reward.</p>
<p>Reinforcement learning has recently garnered significant news coverage as a result of innovations in deep Q-networks (DQNs) by DeepMind Technologies. Through deep reinforcement learning, DeepMind was able to teach computers to <a href="http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html">play Atari games better than humans</a>, as well as <a href="https://en.wikipedia.org/wiki/AlphaGo">defeat one of the top Go players in the world</a>.</p>
<p>As noted in <a href="https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf#page=10">DeepMind’s paper</a>, an “informal search” for hyperparameter values was conducted in order to avoid the high computational cost of performing grid search. Because the complexity of grid search grows exponentially with the number of parameters being tuned, experts often spend considerable time and resources performing these “informal searches.” This may lead to <a href="https://www.nervanasys.com/sigopt/">suboptimal performance</a>, or can lead to the systems not being tuned at all. Bayesian optimization represents a way to efficiently optimize these high dimensional, time consuming, and expensive problems.</p>
<p>We will demonstrate the power of hyperparameter optimization by using <a href="https://start.sigopt.com/">SigOpt</a>’s ensemble of state-of-the-art Bayesian optimization techniques to tune a DQN. We’ll show how this approach finds better hyperparameter values much faster than traditional methods such as grid and random search, without requiring expert time spent doing “informal” hand tuning of parameters. The DQN under consideration will be used to solve a classic learning control problem called the Cart-Pole problem <sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>. In this problem, a pole must be balanced upright on a cart for as long as possible. To simulate this environment, we will use <a href="https://gym.openai.com/">OpenAI’s Gym library</a>.</p>
<p><img src="/cart-pole-5180520f36927208453c56e36ef9f7ce.gif" alt="Figure 1"/>
<em>‍<strong>Figure 1:</strong> A rendered episode from the OpenAI Gym’s Cart-Pole environment</em></p>
<p>The OpenAI Gym provides a common interface to various reinforcement learning environments; the code written for this post (<a href="https://github.com/sigopt/sigopt-examples/tree/master/reinforcement-learning">available on Github</a>) can be easily modified to solve other learning control problems from the Gym’s environments.</p>
<h3>The Environment</h3>
<p>In OpenAI’s simulation of the cart-pole problem, the software agent controls the movement of the cart, earning a <strong>reward</strong> of +1 for each timestep until the terminating step. A terminating step occurs when the pole is more than 15 degrees from vertical or if the cart has moved more than 2.4 units from the center. The agent receives 4 continuous values that make up the <strong>state</strong> of the environment at each timestep: the position of the cart on the track, the angle of the pole, the cart velocity, and the rate of change of the angle. The agent’s only possible <strong>actions</strong> at each timestep are to push the cart to the left or right by applying a force of either -1 or +1, respectively. A series of states and actions, ending in a terminating state, is known as an <strong>episode</strong>. The agent will have no prior concept about the meaning of the values that represent these states and actions.</p>
<h3>Q-learning</h3>
<p>Q-learning is a reinforcement learning technique that develops an action-value function (also known as the Q-function) that returns an expected utility of an action given a current state. Thus, the policy of the agent is to take the action with the highest expected utility.</p>
<p>Assume there exists an all-knowing Q-function that always selects the best action for a given state. Through Q-learning, we construct an approximation of this all-knowing function by continually updating the approximation using the results of previously attempted actions. The Q-learning algorithm updates the Q-function iteratively, as is explained below; initial Q-values are arbitrarily selected. An existing expected utility is updated when given new information using the following algorithm<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup></p>
<p>$$ Q_{t+1}(s_t, a_t) = Q_t(s_t, a_t) + \alpha(r_{t+1} + \gamma \max_a( Q_t(s_{t+1}, a)) - Q_t(s_t, a_t)). $$</p>
<ul>
<li>$a_t$ is the action executed in the state $s_t$.</li>
<li>$s_{t+1}$ is the new state observed. In a deterministic environment<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>, it is a function of $s_t$ and $a_t$.</li>
<li>$r_{t+1}$ is the immediate reward gained. It is a function of $s_t$, $a_t$, and $s_{t+1}$.</li>
<li>$\alpha$ is the constant learning rate; how much the new information is weighted relative to the old information.</li>
<li>$\gamma$ is the constant discount factor that determines how much long-term rewards should be valued.</li>
</ul>
<p>In its simplest form, the Q-function can be implemented as a table mapping all possible combinations of states and actions to expected utility values. Since this is infeasible in environments with large or continuous action and observation spaces, we use a neural net to approximate this lookup table. As the agent continues act within the environment, the estimated Q-function is updated to better approximate the true Q-function via <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a>.</p>
<h3>The Objective Metric</h3>
<p>To properly tune the hyperparameters of our DQN, we have to select an appropriate objective metric value for SigOpt to optimize. While we are primarily concerned with maximizing the agent’s reward acquisition, we must also consider the DQN’s stability and efficiency. To ensure our agent’s training is efficient, we will train the DQN over the course of only 350 episodes and record the total reward accumulated for each episode. We use a rolling average of the reward for each set of 100 consecutive episodes (episodes 1 to 100, 2 to 101, etc.) and take the maximum for our objective metric. This helps stabilize the agent’s learning while also giving a robust metric for the overall quality of the agent with respect to the reward.</p>
<h3>Tunable Parameters of Reinforcement Learning Via Deep Q-Networks</h3>
<p>While there are many tunable hyperparameters in the realm of reinforcement learning and deep Q-networks<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>, for this blog post the following 7 parameters<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup> were selected:</p>
<p><strong>minibatch_size:</strong> The number of training cases used to update the Q-network at each training step. These training cases, or minibatches, are randomly selected from the agent’s replay memory. In our implementation, the replay memory contains the last 1,000,000 transitions in the environment.</p>
<p><strong>epsilon_decay_steps:</strong> The number of episodes required for the initial $\epsilon$ value to linearly decay until it reaches its end value. $\epsilon$ is the probability that our agent takes a random action, which decreases over time to balance exploration and exploitation. The upper bound for this parameter depends on the total number of episodes run. Initially, $\epsilon$ is 1, and it will decrease until it is 0.1, as suggested in DeepMind’s paper.</p>
<p><strong>hidden_multiplier:</strong> Determines the number of nodes in the hidden layers of the Q-network. We set the number of nodes by multiplying this value by the size of the observation space. We formulated this parameter in this way to make it easier to switch to environments with different observation spaces.</p>
<p><strong>initial_weight_stddev</strong> and <strong>intial_bias_stddev:</strong> Both the Q-network’s weights and biases are randomly initialized from normal distributions with a mean of 0. The standard deviations of these distributions affect the rate of convergence of the network.</p>
<p><strong>learning_rate:</strong> Regulates the speed and accuracy of the Q-network by controlling the rate at which the weights of the network are updated. We look at this parameter on the logarithmic scale. This is equivalent to $\alpha$ in the Q-learning formula.</p>
<p><strong>discount_factor:</strong> Determines the importance of future rewards to the agent. A value closer to zero will place more importance on short-term rewards, and a value closer to 1 will place more importance on long-term rewards. This is equivalent to $\gamma$ in the Q-learning formula.</p>
<p>Other good hyperparameters to consider tuning are the minimum epsilon value, the replay memory size, and the number of episodes of pure exploration (<strong>_final_epsilon</strong>, <strong>_replay_memory_size</strong>, and <strong>_episodes_pure_exploration</strong> in the Agent class).</p>
<h3>The Code</h3>
<p><a href="https://github.com/sigopt/sigopt-examples/tree/master/reinforcement-learning">The code is available on Github</a>. The only dependencies required to run this example are NumPy, Gym, TensorFlow, and SigOpt. If you don’t have a SigOpt account, you can <a href="https://sigopt.com/signup">sign up for a free SigOpt trial</a>. SigOpt also has <a href="https://start.sigopt.com/edu">a free plan available for academic users</a>.</p>
<p>Running this code can be computationally intensive. If possible, try running this example on a CPU optimized machine. On a c4.4xlarge AWS instance, the entire example can take up to 5 hours to run. If you are running the code on an AWS instance, you can try using the SigOpt Community AMI that includes several pre-installed machine learning libraries.</p>
<h3>Results</h3>
<p>We compared the results of SigOpt’s Bayesian optimization to two standard hyperparameter tuning methods: grid search and random search<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>. 128 objective evaluations for each optimization method were run, and we took the median of 5 runs.</p>

















<table><thead><tr><th></th><th>SigOpt</th><th>Random Search</th><th>Grid Search</th></tr></thead><tbody><tr><td>Best Found</td><td>847.19</td><td>569.93</td><td>194.62</td></tr></tbody></table>
<p><em><strong>Table 1:</strong> SigOpt outperforms random search and grid search.</em></p>
<p><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:620px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:56.451612903225815%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABRElEQVQoz31TCW6EMAzk/8+sVBXtLrnvg6mdAlpWUEuDTWImzthM67qCjf17vPve+wmfOZ82XZHtcSkFy7JAEIwx5AVqrae8dwzC95M+SQ/wGqFv8Z1x7qiQr+KcOxGcEo3Fammfc9j7gJgrNK1LIaC1HhyjwtYarLUD2Kh6LqghocSM5BLiopFyQ0p1+FxIz+ghlxd+5hlKSsQYhxwTP1gjTYTZRdiHgpwVrHTQwg3vQ4HPdIvU4FNHIMK1EHkItBcQCFwQaz7xQykFJTSWrycCfVBvhfpPwa3LXKGmDi7fM0oqtNTo9HCgZ4ZH9y+sibSMht7dZZe3pvydasQTUT2QrEAOBsFIgkAJLIVCJs34WqxVyfl2Ho+x2YeW0SjOpFFMecS1EWobZFfzejnYu40m0ShwNaytpA5q8rzG4t/9Vbv9AqnwYKv+15q8AAAAAElFTkSuQmCC&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="Figure 2" title="Figure 2" src="/static/edc497acafaa390e075fecbd53fb9191/37dda/best-trace.png" srcSet="/static/edc497acafaa390e075fecbd53fb9191/bc34b/best-trace.png 293w, /static/edc497acafaa390e075fecbd53fb9191/da9f0/best-trace.png 585w, /static/edc497acafaa390e075fecbd53fb9191/37dda/best-trace.png 620w" sizes="(max-width: 620px) 100vw, 620px"/>
    </span>
<em><strong>Figure 2:</strong> The best seen trace of hyperparameter tuning methods over the course of 128 objective evaluations.</em></p>
<p>SigOpt does dramatically better than random search and grid search! For fun, let’s look at the performance of the DQN with the best configuration found by SigOpt. Below are snapshots showing the progress of the sample network’s evolution over the 350 episodes.</p>
<p><img src="/ep64-1a93f0a3bcb4abc946b384773f5a3b33.gif" alt="Figure 3"/>
<em><strong>Figure 3:</strong> Episode 64 of 350. The pole tilts too far, ending the episode.</em></p>
<p><img src="/ep125-019ac1a21272083ea87e7705f602a5c2.gif" alt="Figure 4"/>
<em><strong>Figure 4:</strong> Episode 125 of 350. The cart goes too far in one direction, ending the episode.</em></p>
<p><img src="/ep216-793a5e61ec175b58302a75f7b1accc80.gif" alt="Figure 5"/>
<em><strong>Figure 5:</strong> Episode 216 of 350. The agent performs well. The video cuts off before the agent fails.</em></p>
<p>As shown above, the agent initially has trouble keeping the pole balanced. Eventually, it learns that it can go in the direction that the pole is angled in order to prevent it from falling over immediately. However, the cart would then travel too far in one direction, another failure condition. Finally, the agent learns to move just enough to swing the pole the opposite way so that it is not constantly travelling in a single direction. This is the power of tuning <strong>discount_factor</strong> effectively!</p>
<h3>Closing Remarks</h3>
<p>Through hyperparameter tuning with Bayesian optimization, we were able to achieve better performance than otherwise possible with standard search methods. The example code presented in this post is easily adaptable to explore more computationally intensive tasks. We encourage you to try:</p>
<ul>
<li>Implementing more sophisticated DQN features to improve performance</li>
<li>Tuning a greater number of hyperparameters</li>
<li>Attempting more complicated games from the OpenAI Gym, such as Acrobot-v1 and LunarLander-v0. Our code currently supports games with a discrete action space and a 1-D array of continuous states for the observation space</li>
<li>Tuning a DQN to maximize general performance in multiple environments</li>
</ul>
<p>Let us know what you try!</p>
<p><em>This blog post was originally published on the <a href="https://blog.sigopt.com/posts/using-bayesian-optimization-for-reinforcement-learning#footnotes">SigOpt blog</a>. It is co-written by Olivia Kim.</em></p>
<hr class="footnotes-sep"/>
<section class="footnotes">
<ol class="footnotes-list">
  <li id="fn1" class="footnote-item"><p>We use the version of the cart-pole problem as described by Barto, Sutton, and Anderson. <a href="#fnref1" class="footnote-backref">↩︎</a></p>
  </li>
  <li id="fn2" class="footnote-item"><p>For further insight into the Q-function, as well as reinforcement learning in general, check out <a href="https://www.nervanasys.com/demystifying-deep-reinforcement-learning/">this blog post from Nervana</a> <a href="#fnref2" class="footnote-backref">↩︎</a></p>
  </li>
  <li id="fn3" class="footnote-item"><p>The environment does not need to be deterministic for Q-learning to work. The <a href="http://users.isr.ist.utl.pt/~mtjspaan/readingGroup/ProofQlearning.pdf">proof that Q-learning converges</a> takes into account stochastic environments. <a href="#fnref3" class="footnote-backref">↩︎</a></p>
  </li>
  <li id="fn4" class="footnote-item"><p>DeepMind lists <a href="https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf#page=10">the hyperparameters used in their algorithm</a> to train an agent to play Atari games <a href="#fnref4" class="footnote-backref">↩︎</a></p>
  </li>
   <li id="fn5" class="footnote-item"><p>The types and ranges of the hyperparameters used in this example:
     </p><ul><li><strong>minibatch_size</strong>: integer [10, 500]</li><li><strong>epsilon_decay_steps</strong>: integer [nn/10, nn] where nn is the number of episodes (for the cart-pole problem, this is set to 350)</li><li><strong>hidden_multiplier</strong>: integer [5, 100]</li><li><strong>initial_weight_stddev</strong>: double [0.01, 0.5]</li><li><strong>initial_bias_stddev</strong>: double [0.0, 0.5]</li><li><strong>log(learning_rate)</strong>: double [log(0.0001), log(1)]</li><li><strong>discount_factor</strong>: double [0.5, 0.9999]</li></ul>
     <a href="#fnref5" class="footnote-backref">↩︎</a><p></p>
  </li>
  <li id="fn6" class="footnote-item"><p>We used uniform random search and the vertices of the hypercube for grid search. <a href="#fnref6" class="footnote-backref">↩︎</a></p>
  </li>
</ol></section></div></section><style data-emotion-css="1a0mcpy">.css-1a0mcpy{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 auto;padding:3vw 0 6vw 0;max-width:840px;}</style><footer class="css-1a0mcpy e1upbou20"><style data-emotion-css="k008qs">.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><section class="css-k008qs e14y4vbd0"><style data-emotion-css="2785xc">.css-2785xc{display:block;background:#e4eaed;border-radius:100%;object-fit:cover;margin-right:15px;width:60px;height:60px;}</style><img src="/static/bdab92d9be616df8c1a2cd59aa3d8a9f/f4032/eric.jpg" alt="Eric" class="css-2785xc"/><style data-emotion-css="fz4w57">.css-fz4w57 p{margin:0;color:#738a94;line-height:1.3em;}</style><section class="css-fz4w57 e14y4vbd2"><style data-emotion-css="1eii8n9">.css-1eii8n9{margin:8px 0 2px 0;padding:0;font-size:2rem;}.css-1eii8n9 a{color:#15171A;font-weight:700;}.css-1eii8n9 a:hover{-webkit-text-decoration:none;text-decoration:none;}</style><h4 class="css-1eii8n9 e14y4vbd1"><a href="/about">Eric</a></h4><p>Software enginner. Watches a lot of movies. Doesn&#x27;t drink coffee.</p></section></section><style data-emotion-css="1zye22">.css-1zye22{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;margin-left:20px;}</style><div class="css-1zye22 eew2m8t0"><style data-emotion-css="1hp0auc">.css-1hp0auc{display:block;padding:9px 16px;border:#adbac0 1px solid;color:#738a94;font-size:1.2rem;line-height:1;font-weight:500;border-radius:20px;-webkit-transition:all ease 0.2s;transition:all ease 0.2s;}.css-1hp0auc:hover{border-color:#3eb0ef;color:#3eb0ef;-webkit-text-decoration:none;text-decoration:none;}</style><a class="css-1hp0auc" href="/about">About</a></div></footer></article></div></main><style data-emotion-css="1x0l29j">.css-1x0l29j{position:relative;padding:0 4vw;}</style><aside class="read-next css-1x0l29j"><div class="css-s2cjas"><style data-emotion-css="12kejdt">.css-12kejdt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin:0 -20px;padding:40px 0 0 0;}</style><div class="css-12kejdt e1wiqi0y6"><style data-emotion-css="1kn8487">.css-1kn8487{position:relative;-webkit-flex:1 1 300px;-ms-flex:1 1 300px;flex:1 1 300px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;overflow:hidden;margin:0 20px 40px;padding:25px;color:#fff;background:#15171A center center;background-size:cover;border-radius:5px;box-shadow:rgba(39,44,49,0.06) 8px 14px 38px,rgba(39,44,49,0.03) 1px 3px 8px;background-image:url(/static/f55e924eff608d71da37e57b398c587d/883ab/blog-cover.jpg);}.css-1kn8487:before{content:"";position:absolute;top:0;right:0;bottom:0;left:0;display:block;background:linear-gradient(135deg,rgba(0,40,60,0.8) 0%,rgba(0,20,40,0.7) 100%);border-radius:5px;-webkit-backdrop-filter:blur(2px);backdrop-filter:blur(2px);}</style><article class="css-1kn8487 e1isluuj0"><style data-emotion-css="1d05jhl">.css-1d05jhl{position:relative;z-index:50;padding-top:20px;text-align:center;}</style><header class="css-1d05jhl e1isluuj1"><style data-emotion-css="qbcumt">.css-qbcumt{display:block;font-size:1.3rem;line-height:1.3em;opacity:0.8;}</style><small class="css-qbcumt e1isluuj2">— <!-- -->Eric Bai<!-- --> —</small><style data-emotion-css="y0gtj6">.css-y0gtj6{margin:0;padding:0 20px;color:#fff;font-size:3rem;line-height:1.2em;-webkit-letter-spacing:1px;-moz-letter-spacing:1px;-ms-letter-spacing:1px;letter-spacing:1px;}.css-y0gtj6 a{color:#fff;font-weight:300;-webkit-text-decoration:none;text-decoration:none;}.css-y0gtj6 a:hover{-webkit-text-decoration:none;text-decoration:none;}</style><h3 class="css-y0gtj6 e1isluuj3"><a href="/tags/projects/">projects</a></h3></header><style data-emotion-css="1x76w68">.css-1x76w68{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;height:80px;}.css-1x76w68 svg{width:40px;fill:transparent;stroke:#fff;stroke-width:0.5px;stroke-opacity:0.65;}</style><div class="css-1x76w68 e1isluuj4"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"></path></svg></div><style data-emotion-css="1mqgav7">.css-1mqgav7{position:relative;z-index:50;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-size:1.7rem;}.css-1mqgav7 ul{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;margin:0 auto;padding:0;text-align:center;list-style:none;}.css-1mqgav7 li{margin:0;padding:0;font-size:1.6rem;line-height:1.25em;font-weight:200;-webkit-letter-spacing:-0.5px;-moz-letter-spacing:-0.5px;-ms-letter-spacing:-0.5px;letter-spacing:-0.5px;}.css-1mqgav7 li a{display:block;padding:20px 0;border-bottom:rgba(255,255,255,0.3) 1px solid;color:#fff;font-weight:500;vertical-align:top;-webkit-transition:opacity 0.3s ease;transition:opacity 0.3s ease;}.css-1mqgav7 li:first-of-type a{padding-top:10px;}.css-1mqgav7 li a:hover{opacity:1;}</style><div class="css-1mqgav7 e1isluuj5"><ul><li><a href="/2015-09-11-my-first-android-app-the-development-process/">My First Android App: The Development Process</a></li><li><a aria-current="page" class="" href="/2016-12-09-using-bayesian-optimization-for-reinforcement-learning/">Using Bayesian Optimization for Reinforcement Learning</a></li><li><a href="/2018-05-10-i-made-some-data-visualizations-for-my-girlfriend/">I Made Some Data Visualizations For My Girlfriend</a></li></ul></div><style data-emotion-css="t8u9qr">.css-t8u9qr{position:relative;margin:15px 0 3px 0;text-align:center;}.css-t8u9qr a{color:#fff;}</style><footer class="css-t8u9qr e1isluuj6"><a href="/tags/projects/">See all 4 posts<!-- --> →</a></footer></article><style data-emotion-css="1eugmea">.css-1eugmea{-webkit-flex:1 1 300px;-ms-flex:1 1 300px;flex:1 1 300px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;overflow:hidden;margin:0 20px 40px;min-height:300px;background:#fff center center;background-size:cover;border-radius:5px;box-shadow:rgba(39,44,49,0.06) 8px 14px 38px,rgba(39,44,49,0.03) 1px 3px 8px;-webkit-transition:all 0.5s ease;transition:all 0.5s ease;}.css-1eugmea:hover{box-shadow:rgba(39,44,49,0.07) 8px 28px 50px,rgba(39,44,49,0.04) 1px 6px 12px;-webkit-transition:all 0.4s ease;transition:all 0.4s ease;-webkit-transform:translate3D(0,-1px,0) scale(1.02);-ms-transform:translate3D(0,-1px,0) scale(1.02);transform:translate3D(0,-1px,0) scale(1.02);}</style><article class="post-card  css-1eugmea"><style data-emotion-css="kufnxr">.css-kufnxr{position:relative;display:block;overflow:hidden;border-radius:5px 5px 0 0;}</style><a class="post-card-image-link css-kufnxr" href="/2015-09-11-my-first-android-app-the-development-process/"><style data-emotion-css="8kte6t">.css-8kte6t{width:auto;height:200px;background:#c5d2d9 no-repeat center center;background-size:cover;}</style><div class="post-card-image css-8kte6t edng5gc0"><div class=" gatsby-image-wrapper" style="position:relative;overflow:hidden;height:100%"><div style="width:100%;padding-bottom:61.904761904761905%"></div><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAAC7UlEQVQoz2WTSUyTURRG/2odUBHjPEeN0ThEdGVcqQkhKlGIxiA4LBwIUas0RigKxFIobWkZSotAHSCCgNKCEi11iqBUEK1GLEOhUUM0oi4UNbry+LdFMLq477uLe0++9+59glCowR/mrED4cmMGQl46gkmNUJAZ0KE8M6C+mn/7fDGUiCEZhEXZraS2NhFafYHxJQaCLTmMK9Ez7UI+IedymVNmYkXluQD8r/4A8A9d1JE+zVMS46jj68+fGJ61Ut7VjuO1F/urHiq7X2LzdtP2/i16VwtCrpKRZg1/M4Sh5KwWwaJHKMlm9fUKYhvt7HTUEt5gZcvtOiLv1RN+q5aKng422WtYc63CXyucz0Eozh6G/oEFGZTMPiVnuuI4Y4/sR5DHiQ7OEHxazoQTh5HKDhAkO8h4UxbSDAXTEmXMUiQw+VgcY9OTEIq0AajEdxTrWJqWxOb4OJbtiWZRZAQLt29jsjaNDfGHCN27m7lRW5gftpGgxKOsVMhZvS+WKVERTApbT0jMDhGoG7zyoNWZeiULiw1IC8TpGVWMUp5kovo066ylbGioYsHVcpZctjA6Rc6umnI0T52caL5L2pNmwovyEfJVSHzP5geKdkMyTjFdm8riQh3zCtRIFTLmi2BXWQNJ1R1YGjU4rRdZrMtEd9fBwMA3XvV/4MvAACrbFf+ARviA/lUxqwk1amnr7uKBONH2vjckWauYqknlvrMNndOF8YGN+pt1LNepSLhewwtvL47nLh55upBVlA47HOEDiku71qzn+/t+3n36yK8fPzCLLsYoE7G2NuP0uHno6aGlo4MZ6QqS62309fbi7uzk++cvpPznsDCLVTlqXra7ee7pps/tRlVVziiVAntTI57OLjxeLx/fvmOOOoXoylJMTx+R1+bE4HISe8ky/HMk5gBwebaK1pbH3LjtoCg5mZiTCUgzk0morcYoNheIi6xpusOkM4lsuljE1vqrRDfYCLtmY73ZhGTw1/wGinJQBfLRLIoAAAAASUVORK5CYII=" alt="My First Android App: The Development Process cover image" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/2bfba02af12f673ee6dfb4ec0572b4ba/4c9af/xcerpt-cover.png 930w,
/static/2bfba02af12f673ee6dfb4ec0572b4ba/e914e/xcerpt-cover.png 1860w,
/static/2bfba02af12f673ee6dfb4ec0572b4ba/7c513/xcerpt-cover.png 2100w" sizes="(max-width: 2100px) 100vw, 2100px" /><img loading="lazy" sizes="(max-width: 2100px) 100vw, 2100px" srcset="/static/2bfba02af12f673ee6dfb4ec0572b4ba/4c9af/xcerpt-cover.png 930w,
/static/2bfba02af12f673ee6dfb4ec0572b4ba/e914e/xcerpt-cover.png 1860w,
/static/2bfba02af12f673ee6dfb4ec0572b4ba/7c513/xcerpt-cover.png 2100w" src="/static/2bfba02af12f673ee6dfb4ec0572b4ba/7c513/xcerpt-cover.png" alt="My First Android App: The Development Process cover image" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div></div></a><style data-emotion-css="123mfn9">.css-123mfn9{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}</style><div class="post-card-content css-123mfn9 edng5gc1"><style data-emotion-css="t0tfly">.css-t0tfly{position:relative;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;display:block;padding:25px 25px 0;color:#15171A;}.css-t0tfly:hover{-webkit-text-decoration:none;text-decoration:none;}</style><a class="post-card-content-link css-t0tfly" href="/2015-09-11-my-first-android-app-the-development-process/"><header class="post-card-header"><style data-emotion-css="z4f0wj">.css-z4f0wj{display:block;margin-bottom:4px;color:#738a94;font-size:1.2rem;line-height:1.15em;font-weight:500;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;text-transform:uppercase;}</style><span class="css-z4f0wj edng5gc2">projects</span><style data-emotion-css="8kn4zf">.css-8kn4zf{margin-top:0;}</style><h2 class="css-8kn4zf edng5gc3">My First Android App: The Development Process</h2></header><style data-emotion-css="1pcdrot">.css-1pcdrot{font-family:Georgia,serif;}</style><section class="css-1pcdrot edng5gc4"><p>On August 30th, I released Xcerpt, an Android app for sharing links on Twitter attached with an eye-catching image of some content from the…</p></section></a></div></article><article class="post-card  css-1eugmea"><a class="post-card-image-link css-kufnxr" href="/2018-05-10-i-made-some-data-visualizations-for-my-girlfriend/"><div class="post-card-image css-8kte6t edng5gc0"><div class=" gatsby-image-wrapper" style="position:relative;overflow:hidden;height:100%"><div style="width:100%;padding-bottom:56.266666666666666%"></div><img src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBBAX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAABlyUDolcL/8QAHBAAAQMFAAAAAAAAAAAAAAAAAAECAwQSEzNB/9oACAEBAAEFAmSyNG1NxlU5HtP/xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPwGI/8QAFhEBAQEAAAAAAAAAAAAAAAAAABES/9oACAECAQE/Aa0//8QAGhAAAQUBAAAAAAAAAAAAAAAAAQACECEx4f/aAAgBAQAGPwIl9hZYXIfH/8QAGhABAAIDAQAAAAAAAAAAAAAAAQAhETFREP/aAAgBAQABPyFWJugDZUz8gtDpgDAc8//aAAwDAQACAAMAAAAQgC//xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQMBAT8QsMv/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAIAQIBAT8QHjbv/8QAGxABAAIDAQEAAAAAAAAAAAAAAQAhETFhUbH/2gAIAQEAAT8Q1Uq3hx0T5M8CKKc9LhYA8VCXLYew1AAIBqohP//Z" alt="I Made Some Data Visualizations For My Girlfriend cover image" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/267dd366f0fc2d1c56a6b041a731b628/f8f18/eric-and-camille.jpg 930w,
/static/267dd366f0fc2d1c56a6b041a731b628/2a5e2/eric-and-camille.jpg 1500w" sizes="(max-width: 1500px) 100vw, 1500px" /><img loading="lazy" sizes="(max-width: 1500px) 100vw, 1500px" srcset="/static/267dd366f0fc2d1c56a6b041a731b628/f8f18/eric-and-camille.jpg 930w,
/static/267dd366f0fc2d1c56a6b041a731b628/2a5e2/eric-and-camille.jpg 1500w" src="/static/267dd366f0fc2d1c56a6b041a731b628/2a5e2/eric-and-camille.jpg" alt="I Made Some Data Visualizations For My Girlfriend cover image" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div></div></a><div class="post-card-content css-123mfn9 edng5gc1"><a class="post-card-content-link css-t0tfly" href="/2018-05-10-i-made-some-data-visualizations-for-my-girlfriend/"><header class="post-card-header"><span class="css-z4f0wj edng5gc2">projects</span><h2 class="css-8kn4zf edng5gc3">I Made Some Data Visualizations For My Girlfriend</h2></header><section class="css-1pcdrot edng5gc4"><p>I just finished my undergrad last month, and it’s really sinking in how special and fleeting the past five years have been. I’m privileged…</p></section></a></div></article></div></div></aside><style data-emotion-css="p382uv">.css-p382uv{position:relative;padding:0 4vw;position:relative;padding-top:20px;padding-bottom:60px;color:#fff;background:#000;}</style><footer class="css-p382uv"><style data-emotion-css="fcb8o">.css-fcb8o{margin:0 auto;max-width:1040px;width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:rgba(255,255,255,0.7);font-size:1.3rem;}.css-fcb8o a{color:rgba(255,255,255,0.7);}.css-fcb8o a:hover{color:rgba(255,255,255,1);-webkit-text-decoration:none;text-decoration:none;}@media (max-width:650px){.css-fcb8o{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}}</style><div class="css-fcb8o"><section class="copyright"><a href="/">Eric Bai</a> © <!-- -->2020<!-- --> </section><style data-emotion-css="j0kq43">.css-j0kq43{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}.css-j0kq43 a{position:relative;margin-left:20px;}.css-j0kq43 a:before{content:'';position:absolute;top:11px;left:-11px;display:block;width:2px;height:2px;background:#fff;border-radius:100%;}.css-j0kq43 a:first-of-type:before{display:none;}@media (max-width:650px){.css-j0kq43 a:first-child{margin-left:0;}}</style><nav class="css-j0kq43 e1iahsxi0"><a href="https://www.facebook.com/TheEricBai" target="_blank" rel="noopener noreferrer">Facebook</a><a href="https://twitter.com/BaiEric" target="_blank" rel="noopener noreferrer">Twitter</a><a href="https://instagram.com/baieric" target="_blank" rel="noopener noreferrer">Instagram</a></nav></div></footer></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/2016-12-09-using-bayesian-optimization-for-reinforcement-learning/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-bf8ae29db75040b27dc0.js"],"component---src-templates-index-tsx":["/component---src-templates-index-tsx-0a38ac376a5513c4cb21.js"],"component---src-templates-post-tsx":["/component---src-templates-post-tsx-39d6e0ff64388c07caf2.js"],"component---src-templates-tags-tsx":["/component---src-templates-tags-tsx-83f6fcb5bcbd68bbc116.js"],"component---src-templates-author-tsx":["/component---src-templates-author-tsx-f2f95296795955e758c4.js"],"component---src-pages-404-tsx":["/component---src-pages-404-tsx-d2cd40456d41d5fb33c0.js"],"component---src-pages-about-tsx":["/component---src-pages-about-tsx-f88f4ad0619becef3536.js"]};/*]]>*/</script><script src="/component---src-templates-post-tsx-39d6e0ff64388c07caf2.js" async=""></script><script src="/commons-db7b0b291fe23d606362.js" async=""></script><script src="/app-bf8ae29db75040b27dc0.js" async=""></script><script src="/webpack-runtime-4931bb6d0f65d2af2d29.js" async=""></script></body></html>